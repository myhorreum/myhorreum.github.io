03/10/20 (day 1) :

I came in 15 minutes early and met with Thomas, my supervisor and one of the people who interviewed me for the position. I was taken to the
office I would be doing my work in and introduced to the laptop (Dell) which I would be doing all work on. I was guided through the process of
setting up my uhtasi email specific and viber messaging accounts.

I was also introduced to my primary task which was to move many TASI web domains under the control of a web hosting panel. Thomas told me that 
the project should be done within a month. I was tasked with performing research on potential panels. I looked through paid panels such as cPanel
and Hosting Controller, as well as open source options such as Ajenti, VestaCP, and Webmin. I created a spreadsheet comparing and contrasting
various attributes the panels had with each other.

We ultimately chose to try out Webmin first. I also was interested in Hosting Controller, but had trouble finding info on how many domains were
allowed on its service as well as the cost of the service. I emailed them inquiring about it as well as planned to potentially test a demo of 
their service later on down the line (after working with Webmin).

03/11/20 (day 2) :

The night before day 2 I did further research on Webmin and found that Virtualmin is actually the web hosting panel service of Webmin. I reported
this info to Thomas and we decided to work with Virtualmin. Interestingly, the Virtualmin download also includes Webmin functionality (you can
toggle between Webmin and Virtualmin). 

Before any downloads, Thomas introduced me to TASI's vCenter. vCenter Server is the centralized management utility for VMware, and is used to manage
virtual machines, multiple ESXi hosts, and all dependent components from a single centralized location. The VMWare is used to create template Virual
Boxes for use. TASI uses Virtual Boxes to test software they have interest in before deciding to use it. In this case we created a Linux CentOS template. 
The template generates an IP address that can be accessed from other computers. I used this IP address to work in the box from my workspace laptop. 

Back on my laptop, I went to VMWare (had to disable the block on Flash in Chrome, also what will happen to VMWare once Chrome abandones Flash??) in
order to work with the Virtual Box environment. Note to log into VMWare I used a uhtasi account to gain access. I connected to the VMware remote
console which essentially connected my monitor to the server. My immediate goal was to get the networking going.

Since I was working on CentOS, I used the terminal command nmtui to set the IP address of our Virtual Box to a specific value and the netmask as
255.255.255.0. After changing this info, you must reset the network using the command systemctl restart network.service. 
To test if the box had internet I pinged 8.8.8.8 (Google).

Once the network was set up I used the IP address of the box to log in through PuTTY. I then changed the hostname and the root password to one of my choice 
using hostnamectl set-hostname your-new-hostname and sudo passwd root.

03/12/20 (day 3) :

My primary task for the day was to install Virtualmin/Webmin and test it out. Through PuTTY I tried to use wget to get the download script, however
wget was not available in PuTTY. To solve this, I used sudo yum install wget. However to complicate things further, yum was not working. I was
getting Yum Command Fails with “Another app is currently holding the yum lock”. I used Google to help solve this. It told me to use the ‘ps -ef’ command
to check for the PID being occupied by yum (it will be shown next to grep). All I had to do to fix this was use kill -9 13023 to stop the hold-up.

wget was finally working (note I did not go with curl because it was not getting me the script effectively). I then used sh install.sh to run the 
install script. Another problem did arise during the installation process. I was getting the message that my hostname server was not fully qualified.
I did research on FQDN (Fully Qualified Domain Name) and learned that I needed to update the /etc/hosts file. I had to put in the hostname and IP
of the server we had set up for Virtualmin use (the one we were currently logged in to PuTTY with). I updated the file with vi. I want to mention
that I exited vi without properly saving before editing how I wanted to; this auto-created a /etc/hosts.swp file. When using vi on the /etc/hosts
file, it gives the option of loading the /etc/hosts.swp file. To rid of this, simply use rm to delete the swap file. Also be sure your hostname 
matches the hostname in the file that you do vi on, or else it will not work.

Virtualmin was finally installed and we got to test it with a web address generated from our IP address. After experimenting with Virtualmin and 
Webmin, my manager and I were not making too much progress. We were confused on exactly what Virtualmin was trying to do. All we wanted was a place
to centrally manage existing web servers, while Virtualmin seemed to simplify new deployments of domains by auto creating a lot of stuff, 
overcomplicating a lot of what we were wanting to do. It seemed we might be getting more than we bargained for. However, at the end of the day,
before deciding to move on from Virtual/Webmin, we opted to do further research on them to see if it was still possible to do we wanted to do 
initially.

03/16/20 (day 4) :

Since Webmin/Virtualmin seemed to be too bulky for our needs, I recommended using ISPConfig. The installation process for ISPConfig was a bit more
lengthy, however I pushed through it much faster this time due to my experience installing Virtualmin. Towards the end of my work session, ISPConfig
was up and running and I added a test server to the domain listing. Thomas wants to see if Apache server integration is possible.

At home, I did further research on ISPConfig. I payed the $5 fee for the ISPConfig manual, and began studying it. It is apparent that 
"admin, clients, and resellers" are a big aspect of ISPConfig. These are three customizable user levels offered by ISPConfig. As of right now, it
does not seem like we will have use for client and reseller roles, though they do seem interesting. We should focus on admin because that gives full
control over the system. Currently I am studying 4.5.4 Domains section of the manual.

03/17/20 (day 5) :

I sent the ISPConfig manual to Thomas. He spent some time studying it before ultimately coming to the conclusion that it was very similar to Webmin.
Therefore, we deemed it best to abandon ISPConfig. Thomas told me to research Ansible, since Miguel had used it in the past. Ansible is a IT 
configuration and management tool used in organizing and even automating tasks.

At home, I looked into Ansible more. I found it had a GUI version called Ansible Tower created in response to the community wanting one. I would
present this info to Thomas tomorrow.

03/18/20 (day 6) :

I told Thomas about Ansible Tower and he believed it came with a price to use, so he told me to look at "regular" Ansible to see if I could find a
work-around, perhaps with plug-ins. I told him that Red Hat had taken over Ansible and that it does not seem to have a free option anymore. Finally
Thomas went to Miguel to figure out exactly what he wants in regards to web hosting control. It seemed that not even Miguel knew totally what he
wanted, he had no concrete idea in place. So, while Miguel figures that out, Thomas told me to move on to a new project: Windows Server Update Services.
Windows Server Update Services (WSUS) enables administrators to manage the distribution of updates and hotfixes released for Microsoft products to 
computers in a corporate environment.

I did research on this while waiting on Jose to configure the environment for me to work in.

03/19/20 (day 7) :

Today I was to configure and test out WSUS. I would do testing on a virtual server created in vCenter. I connected to this server through Remote 
Desktop Connection, which is like giving me access to another computer (in this case server). This server had WSUS installed by Jose. In WSUS, I 
was able to see the created group WSUSTest which had several computers from the TASI offices. Following an online guide, I checked for updates for
these computers and then updated them. I attempted to generate a report but could only generate the basic Computer one, not the detailed report option.
It seemed that WSUS had issues with timing out. I used Event Viewer and found the log of the connection failure. I Googled the Error: Connection Error,
Reset Server Node issue and found it to be a fairly common issue online. One solution would be to go into IIS (Internet Information Services) and
give WSUS access to unlimited memory. For some reason, the server was blank. I think Thomas then tried to move me to an admin role, however it was
still blank. I then searched IIS, right clicked it, and selected to access it as administrator, which then gave me the server. I finally gave WSUS
more memory.

However I still was getting the same issue with connection. Another guide told me to remove the WSUS Adminstration file under Sites in IIS. This did
not work either and actually seemed to break WSUS completely (the connection error was now permanent). I tried to reset the file (it was unlikely
deleted, so I would have to find and repoint it), but I had too much difficulty. I wanted to revert to a previous vCenter snapshot, but Thomas had
not taken one. Jose ended up reconfiguring it back to the original state and took a snapshot. I was now to rework with this again tomorrow.

03/20/20 (day 8) :

Along with giving WSUS unlimited memory in IIS, I also deleted the wsus file under %appdata%\Microsoft\MMC\. This seemed to work, however I was still
experiencing intermittent Error Connection incidents. I fixed this by going back to IIS and setting the Status of WsusPool to Stopped, waiting a bit
(you may get an error notification) and then setting it to Started again. This allowed me to view Updates and Approve them. Also when viewing Computers,
I am able to click on an individual computer and view its Detailed Computer Status Report. This shows the history record of Updates passed to this computer,
and shows the Approval, and the Status on whether it was Not Installed or Downloaded. This brought up the question as to when the Updates will be downloaded.
Are they put in a queue and done based on time? 

Also I want to mention that if you go to Updates and individually click an update, you can view its Detailed Update Status Report. I think what was causing
the crash was that I was previously trying to view them in bulk, which was overwhelming the connection and causing a time-out. 

Lastly, I looked into automating the update install process. I went to Options in the WSUS GUI and went into Automatic Approvals. I created a new rule
called WSUS Test Custom-Auto. I also noticed that within that rule I could customize update download deadlines. I set this to download "the next 
day after the approval at 3:00AM". I assume this will cause the download to be force installed at that time. Link with info :

https://docs.microsoft.com/de-de/security-updates/windowsupdateservices/18127631

However, unfortunately, when clicking the Run Rule, I get a Error Connection timeout after a bit of waiting. 

03/23/20 (day 9) :

I got in and tested the WSUS Automatic Approval that was not working yesterday. To my happiness, it worked without a problem. Thomas seemed happy with
my progress. He now wanted me to research on whether WSUS was capable of automating the Automatic Approval and report generations. Do I have to click
"Run Rule" each time, or is it possible to get it to do that on its own? Also can I create reports after each update cycle automatically, without me
having to do it physically? And can these reports be sent (possibly via email) without me having to do it myself? Surely there must be a way.

Also from now I was to be working remotely, from home, because of COVID-19. I am able to take my work laptop home. However Thomas had me install Dell
SonicWALL NetExtender. This would allow me to connect to uhtasi's VPN server from home, which runs continuously. I was to use Remote Desktop Connection
through this VPN connection.

03/25/20 (day 10) :

Working from home, I logged in via the methods described above. Now in WSUS, I could see in the WSUS Test computer group that the Last Status Report
had been updated since I had worked last time (for some workstations). I clicked on these workstations to view the report. To my dismay the workstation
was still stuck on where it last updated (Microsoft Silverlight). It is approved to Install but the status is that it is Not Installed.

How can I get past this?

I went back to the Automatic Approval Rule that I had set earlier. I noticed that it is only running for updates that fall in the Critical Updates and
Security Updates categories. The Microsoft Silverlight was categorized as Feature Packs. I changed the Auto Rule I created to encompass All Classifications,
not just the two specific categories I had prior. Maybe this will make a difference. I clicked Run Rule and I will check in a couple days.

However I was getting the Error Connection timeout. I restarted the WSUS Pool multiple times, but still was getting the timeout. I will come back to this
in the future, perhaps tomorrow or even back in Saunders itself.

Now I will move on to automating the email reports (having them sent via email automatically). I found a model PowerShell script online that I could use
for our use-case. 

https://www.experts-exchange.com/articles/27419/How-to-send-automatically-an-e-mail-with-a-report-of-computers-status-inside-WSUS-server.html

After modifying our needed credentials, I used Task Scheduler to run the script once a day to test it. However for troubleshooting purposes, I
began just executing the script by hand through its icon on the Desktop. To check if the email was actually being generated and sent to me, I went
to log in to my account back on the regular computer, however I was getting shut out from loggin. Thomas told me that this had to do with the VPN I
was going through. He rewired something and I could now get into my email. However the PowerShell email was not there. I had to do some reconfiguring.

Thomas sent me two scripts he had made himself in the past that had email functionality. Tomorrow I will look through them more indepth to see if I
can use them to help my own script.

03/27/20 (day 11) :

I got into the server and checked the Computer Status report to see if the Microsoft Silverlight had possibly changed at all. It hadn't, as I expected.
However the Status of the updates below Microsoft Silverlight (the ones that were previously Installed), have shifted to "Pending Reboot".

I moved on to try to run the Automatic Approval rule I could not run yesterday. Today it ran on the first time and gave the message that 777 updates
were approved. I will see if this gets the Microsoft Silverlight to finally change its Status to Installed.

I moved on to working with the PS Script. I took out the top smtp variables and focused on the bottom of the script (the Send Mail portion) and had
it match the one Thomas sent me. To my happiness, it worked and the email was in my mailbox. However, raw HTML was in the email which made it near
unreadable. I worked on fixing it. I realized that I had deleted the BodyAsHTML tag without knowing what it did. I put it back and the HTML was now
working as actual HTML and I could see the report in the table format as intended. I sent an email to Thomas as well and he was pleased.

Looking forward I want to see if I can possibly add a list of updates to the report. I also want to look to see what else PowerShell is capable of.
I could look into automation further, because I am still not certain if I need to click "Run Rule" manually every time. I also put the script into Task
Scheduler and set it to run weekly (Mondays at 12:59 PM).

03/30/20 (day 12) :

The emailed report was different from the first report, which showed that some updates went through. However when I went to check the generated reports
in WSUS, it was timing out and resetting the IIS pool did nothing. In the meantime I went to look at another way to use PowerShell scripting to 
obtain updates. It seems that I am transitioning more and more away from WSUS itself and more to PowerShell, since WSUS seems to have issues. I found
a whole slew of WSUS oriented cmdlets in Microsoft documentation:

https://docs.microsoft.com/en-us/powershell/module/updateservices

I looked more closely at Get-WsusUpdate. In PowerShell I ran the command quickly and all the updates on the system began printing onto the screen. I 
terminated the program because it was running on and on due to the thousands of updates shared between the workstations. I looked deeper and learned you
can use tags to only get updates based on attributes. Next work day I want to print updates that are Approved. Can I print updates that are both Approved
to Install and Installed or Approved to Install and Not Downloaded?

If I can get this going, I can eventually convert it into script form and put it into Task Scheduler to automate it. Then I would have two scripts running
based on WSUS reporting.

04/01/20 (day 13) :

Instead of using two separate scripts (the table-based report I got online and the list-of-updates I hoped to build myself), I realized it was probably
best to instead merge them into one. I wanted to figure out a way to possibly add the updates to the bottom of the report, underneath the table.

I received assistance from this guide :

https://devblogs.microsoft.com/scripting/get-windows-update-status-information-by-using-powershell/?irgwc=1&OCID=AID2000142_aff_7593_1375745&tduid=(ir__nkwgz0avcskfrkdtkk0sohziz22xnwu3rk6y206600)(7593)(1375745)()()&irclickid=_nkwgz0avcskfrkdtkk0sohziz22xnwu3rk6y206600

But ultimately could not get the script to work.

Also my NetExtender was not connecting. Thomas told me that NetExtender is notorious for this and told me how to remedy it. To resolve open Task Manager, 
go into Details tab, right click the NEGui.exe process and click End Process Tree, then go into the Services tab and right click the SONICWALL_NetExtender
service and click Start/Restart. If this does not work, try rebooting.

04/06/20 (day 14) :

I found another guide that had potential to be useful :

https://4sysops.com/archives/wsus-reporting-with-powershell/

I brought the script over and modified it to match my WSUS server. However, it would not run. Also, the errors in the PowerShell console were appearing
only for a split second before the console would close, which made it impossible for me to read the errors. I learned online that you can add a tag
at the end of the script for it to stay on the screen. I did this and could now read the errors. The error was coming from the wsus object that I had
created which was supposed to allow connection to the server. However it was saying the the remote connection could not be resolved. All the errors
afterwards were related to this, saying that the methods could not be called on a null-object (wsus). This was strange because the other script I had
been using used pretty much the exact code and was working. I asked Thomas and he led me through several troubleshooting methods but none worked. Tomorrow
I was to send him the script so he could try and figure it out himself.

04/07/20 (day 15) :

I showed Thomas the script and the methods he were going through were not solving the issue. He told me to also do all editing/troubleshooting in 
PowerShell ISE. This would eliminate the console closing suddently upon running the script and trying to see errors. Also it is superior to Notepad
because it highlights the syntax upon other things. 

Finally Thomas managed to identify the error. At the bottom of the script, where it ran the function, it could not identify the tag "wsus" for some
reason. I changed this to localhost as Thomas said and it now worked. However, after some time, the script timed-out. Specifically the GetUpdates
function operation timed-out individually for each call it was used. None of it was working. This is especially unfortunate because I was using 
PowerShell to get around the timing-out found with the WSUS software itself. So now we were back at square one.

To solve this, perhaps instead of looping through computers I could just try and work with one computer. However, upon thinking about this, it seems
the GetUpdates operation is actually being called individually upon each computer anyway, and is timing out (which is why the console has many timeout
errors after a certain amount of time - one timeout per computer). I think another way to approach solving this would be to clean out the WSUS update
database. There could be many updates that are outdated that are clogging up the database. Clearing this could solve the timeout issues. 

Online there are many cleanup scripts available. I tried one but could not get it to work. I ended up just using the built-in WSUS cleanup functionality.
However before the end of the day it did not finish its process, so I logged out without completing it. I will try again tomorrow.

04/09/20 (day 16) : 

I found another script online that looked promising. I downloaded it, but when I attempted to run it, it required a different execution policy. To
change this you have to go to PowerShell and run as administrator. Once you do this, you can use a command to change the Execution Policy for your
local computer. I changed this to Unrestricted which allows all scripts to run no matter what. You can also use a list command to view the policies
for each machine on the system.

However when I ran this script nothing was printing or happening, and I had no idea if it was working at all. I ended up going back to WSUS itself
and ran the cleaner wizard there. I began just running individual sections of updates instead of all at once to see if it made a difference. I
realized that it was freezing specifically on unneeded update files and unused update files. Looking at the stats on the other WSUS page, this makes
sense because there are over 100,000 updates in the database. It seems like all these updates are clogging the database, and when the computer tries
to clean/eliminate them, it just becomes overwhelmed.

I need to find a way to fix this database overpopulation.

04/14/20 (day 17) : 

I got the Adam script that is supposedly the best WSUS script around. After downloading it, I read that the only variable configuring needed to be
done were the email variables. I then went to run the script in Powershell admin ISE. I changed the Execution Policy to Bypass and ran the script
with the First Run tag. The script ran quickly, but had errors linked to an SQL related cmdlet not being installed. I then read in the script that 
you must have SQL Server Management Studio (SSMS) installed. I went online and downloaded it, but it would not install when double clicked because
it said that no program on the PC can open it. Online, I saw that a tutorial where the user first downloads the main SQL server, and then the SSMS.
I did this and then it seemed like I could now install the SSMS, but I was getting a lot of problems. I tried working with Task Manager to no success.
I ended up reverting to my last snapshot of the server. Thomas told me to see if the SSMS was not running because it was blocked. I went right-clicked
it, went into Properties, and saw that it did seem to be blocked. I un-blocked it and the installation was going through. However at the end, it said
that there is not enough disk space. I'm not sure how to fix this because I don't know what to delete on the server to free up space. 

04/15/20 (day 18) : 

To free some space I went to delete accumulated logs in C > Windows > Logs > CBS, as recommended by Thomas. You don't have to go through command line
to do this, you can just go through File Explorer. After deleting the logs, I went to install SSMS again. The install went through. However when I 
went to run the SSMS program, I was getting a weird obscure error that seemed to relate to missing configuration files. I did some research but was
confused on how it was not working or how to solve it. I happened to look at my disk space and realized that I had 0 bytes available to work with.
I was completely maxed out. This probably had something to do with the error. I realized that I would have to clear out more space in order to use
SSMS.

I downloaded and used WinDirStat. WinDirStat is a tool that shows disk-use storage by percentage. It is a useful tool to see what is taking up space
and where. After it ran, I was shocked to see that one file was taking up half of the entire disk space. The file was SUSDB.mdf and it was occupying
26/52 GB on the disk. I looked it up and learned that SUSDB.mdf was actually the WSUS database. It was incredibly bloated but I was glad to be able to
see it.

Thomas told me that he could extend the disk space, but then he asked if there were actually other drives on the system. I said yes, all the disks on
the system are: Local Disk (C), Data (E), and Directory (Z). Everything was stored on C, including all WSUS related files. Thomas told me that the E 
disk should actually be used to store WSUS updates. Thomas told me that it would be preferred for me to move WSUS to the E disk and have it update from
there permanently.

I did research and found a way to do this through Microsoft Documentation:
https://docs.microsoft.com/de-de/security-updates/windowsupdateservices/18127395

The command is wsusutil movecontent contentpath logfile, where contentpath and logfile are to be customized. I had trouble creating the path to the E
disk, the syntax of it was tripping me up. I realized the best way to do this was wsusutil movecontent E:\WSUS E:\WSUS\log.txt. I created a WSUS folder
within E. The command worked successfully and the command line told me that WSUS has been moved.

I began looking for the SUSDB.mdf file out of curiosity, to see if it was now in E. It was not. Neither could I find it in a File Explorer search. I
then used WinDirStat again and realized I had much more space now. But where was the SUSDB.mdf file? Tomorrow I will see if this impacts anything, and
I will proceed with SSMS and the clean-up script.

04/16/20 (day 19) : 

For some reason the C disk was still maxed out, and the SUSDB.mdf file was no where to be found. I chose to extend the disk. Thomas had to give more
available memory. To do this he had to merge all snapshots. Once it was done, I used this guide, which was pretty straightforward :

https://docs.microsoft.com/en-us/windows-server/storage/disk-management/extend-a-basic-volume

With the extra 10 GB of space on the C drive, I could now install SSMS without any problems. Once installed, I went to the PowerShell ISE to run the
script, it was not working for the sqlcmd. I then read through the script and learned that, at the bare mininum, I need these installed for the script:

SQL 2012/2014 - Version 11 - https://www.microsoft.com/en-us/download/details.aspx?id=36433
                      - ODBC Driver Version 11 - https://www.microsoft.com/en-gb/download/details.aspx?id=36434

However the ODBC Driver could not be installed on this operating system. For the Command Line Utilities 11 for SQL Server, it requires the ODBC Driver.

The other problem is that the SUSDB.mdf file should actually be moved to the new location. I used this guide :

https://www.tecknowledgebase.com/33/how-to-move-wsus-content-and-database-files-to-a-different-volume/

However the Servername: \\.\pipe\MSSQL$MICROSOFT##SSEE\sql\query was not connecting.

Lastly, I ran the WSUS software, but it would not load and this was due to a Database Error. I assume that the Database Error is from the missing
SUSDB.mdf file.

There is a lot of fixing up to do...

After thinking about things I thought of this :
1. Maybe the missing SUSDB.mdf file is because I don't have SQL Server downloaded? I only have SSMS downloaded.
2. Maybe the Servername: \\.\pipe\MSSQL$MICROSOFT##SSEE\sql\query is not connecting because of SQL Server not being downloaded?
3. Maybe the OBDC is because of the SQL Server not downloaded as well?

04/17/20 (day 20) : 

From reddit, a user told me that the Servername has been updated for newer OSes. I decided to go for his recommendation and it worked. This was
the new path :

\\.\pipe\MICROSOFT##WID\tsql\query

So I was in and I could see the directories including the SUSDB.mdf file that I could not find previously. I followed the guide I listed from the
previous day and got up to step 6 : Move the database files to the new drive or location where you are planning to keep it.

The reason why I was stuck was because I could not find the SUSDB.mdf outside of SSMS. Using File Explorer, nothing could be found. I tried looking
in Properties of the SUSDB.mdf file in SSMSS itself, but I was getting an error that would not allow me to see the Properties. Then, I looked online
and found a path that could potentially work, it was :

C > Windows > WID > Data

To my happiness, the path in fact did lead me to the SUSDB.mdf file.

Now, I had to move it from its current location in the C drive to the E drive where I want it to be. Initially, I had an error saying that I could 
not move the SUSDB.mdf file because because the file is open is another program. To fix this I had to kill the sqlservr.exe proccess. After this, I
could now move the files to the E drive.

However when I went back to SSMS, an error was coming up where the connecton to the database had been broken. Now nothing was working.

I think this had to do with me stopping the sqlservr.exe. In Task Manager, you can look at the Services tab, maybe it will be in here to get it to
start working again. Also I noticed WsusService was stopped as well. I may have to start this again further down the line. (Also don't forget that
I disabled the update services and the IIS). The update services could be the same as the WsusService.

However I could not find a way to restart sqlservr.exe

04/20/20 (day 21) : 

Back in Task Manager, I was looking around to see if I could find any way to restart the sqlservr.exe. Curiously, I came across MSSQL$MICROSOFT##WID
in the Services tab. This stuck out to me because I knew the sqlservr.exe was located in the Windows\WID\Binn file path. Note that WID stands for 
Windows Internal Database. Also, it was stopped.

I restarted it and its Status was now Running. I went back to SSMS and I was no longer getting the database error, so I knew that I had fixed it.

Now, before attaching the new SUSDB.mdf in SSMS, I wanted to delete the orininal copy in C > Windows > WID > Data. This is because it would be pointless
to have two copies, and the C disk should not have this file anyway (which is why we are doing this whole process of moving the file). I told Thomas
to take a Snapshot of the server before deleting the files.

I went to attach the new SUSMD.mdf in the E drive, however I was getting an error. I looked up a guide online and changed the properties of the SUSMD.mdf
to allow Users full access rights. However when I went back to attach it, I got another error. If you scroll right, you can see what type of error it is 
in the Message column. It said that I cannot attach a database with the same name. This is because the SUSDB.mdf both are named the same in the C and E drives,
obviously. I went to remove the SUSDB.mdf reference in the C file structure in SSMS, however I got an error saying the file is not found. I assume this is
because I deleted it earlier. 

I need to figure out how to fix this. I told Thomas to revert back to before I deleted the SUSMD.mdf file.

04/21/20 (day 22) : 

After reverting back to the Snapshot-ted state, I was back to having to detach the old SUSMD database. Remember to be running SSMS as admin while doing
this. Once detached, I went to attach the new database in the E drive. When trying to attach I initially had a problem, the error message was saying
something about read-only permissions. To fix this, I went to the WSUS folder I created in E drive (I was outside the folder). I right-clicked the
folder and went to Properties > Security. I then give Users full permissions. I got an error message about the log.ldf file but did not look at it too
deeply.

Back at the SSMS, I tried to attach again, but it did not work. It said that the .ldf file was the source of the problem. I went back the to E drive
to get to the .ldf file. I right-clicked on the file individually and noticed its User permissions were not fully set, I fully set them and the attach
went smoothly.

Note that when you detach, the SUSDB.mdf disappears, but when you attach, it reappears.

I then told Thomas to take a Snapshot because I want to delete the old SUSDB.mdf on the C drive.

Once the Snapshot was completed, I deleted the two duplicate files. I then remembered to restart Windows Update and IIS. I restarted IIS through command
prompt. Also, in Task Manager, I noticed WsusService and WSusCertServer were Stopped, so I set them to Running.

However when I went to run WSUS, it would not load the workstations or updates. I did more research online and came across this guide, and while I don't
think it completely matches this use-case, it has additional steps which I think are worth working through:

https://docs.microsoft.com/en-us/windows-server/administration/windows-server-update-services/manage/wid-to-sql-migration

I stopped Update Services and IIS again (using PowerShell, since its easier) and went through the later portions of the guide. 

I stopped before the "Edit the registry to point WSUS to the SQL Server Instance" of the guide.

Also, I learned that SSMS has an internal activity monitor. I utilized it, and interestingly could see a jump in activity when I initiated WSUS.
I guess this means that they are interacting with one another, but the connection is still failing.

It may be best to revert to before the moving of the databases.